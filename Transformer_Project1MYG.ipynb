{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "tGVTjPBi5XeV",
    "outputId": "458af3a1-7e58-4015-deb0-9f930f0541e9"
   },
   "outputs": [],
   "source": [
    "file_path = \"mcts_nn_dataset_2_Feb.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ULtgutfLE-sM",
    "outputId": "24582eda-6902-424f-fb4a-8545d85103b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1125s\u001b[0m 1s/step - accuracy: 0.2494 - loss: 1.7964 - val_accuracy: 0.3577 - val_loss: 1.5412\n",
      "Epoch 2/20\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1191s\u001b[0m 2s/step - accuracy: 0.3645 - loss: 1.5369 - val_accuracy: 0.3863 - val_loss: 1.5030\n",
      "Epoch 3/20\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1113s\u001b[0m 1s/step - accuracy: 0.3941 - loss: 1.4891 - val_accuracy: 0.4116 - val_loss: 1.4573\n",
      "Epoch 4/20\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1209s\u001b[0m 2s/step - accuracy: 0.4170 - loss: 1.4495 - val_accuracy: 0.4230 - val_loss: 1.4336\n",
      "Epoch 5/20\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1095s\u001b[0m 1s/step - accuracy: 0.4287 - loss: 1.4271 - val_accuracy: 0.4307 - val_loss: 1.4205\n",
      "Epoch 6/20\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1058s\u001b[0m 1s/step - accuracy: 0.4375 - loss: 1.4063 - val_accuracy: 0.4390 - val_loss: 1.4049\n",
      "Epoch 7/20\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1056s\u001b[0m 1s/step - accuracy: 0.4446 - loss: 1.3928 - val_accuracy: 0.4423 - val_loss: 1.3941\n",
      "Epoch 8/20\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1063s\u001b[0m 1s/step - accuracy: 0.4520 - loss: 1.3787 - val_accuracy: 0.4441 - val_loss: 1.3888\n",
      "Epoch 9/20\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1064s\u001b[0m 1s/step - accuracy: 0.4560 - loss: 1.3681 - val_accuracy: 0.4521 - val_loss: 1.3749\n",
      "Epoch 10/20\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4060s\u001b[0m 5s/step - accuracy: 0.4592 - loss: 1.3590 - val_accuracy: 0.4488 - val_loss: 1.3835\n",
      "Epoch 11/20\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8028s\u001b[0m 10s/step - accuracy: 0.4644 - loss: 1.3495 - val_accuracy: 0.4530 - val_loss: 1.3716\n",
      "Epoch 12/20\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6246s\u001b[0m 8s/step - accuracy: 0.4681 - loss: 1.3398 - val_accuracy: 0.4559 - val_loss: 1.3664\n",
      "Epoch 13/20\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5070s\u001b[0m 6s/step - accuracy: 0.4704 - loss: 1.3340 - val_accuracy: 0.4573 - val_loss: 1.3576\n",
      "Epoch 14/20\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3131s\u001b[0m 4s/step - accuracy: 0.4743 - loss: 1.3260 - val_accuracy: 0.4588 - val_loss: 1.3580\n",
      "Epoch 15/20\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9590s\u001b[0m 12s/step - accuracy: 0.4747 - loss: 1.3207 - val_accuracy: 0.4598 - val_loss: 1.3576\n",
      "Epoch 16/20\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5570s\u001b[0m 7s/step - accuracy: 0.4788 - loss: 1.3151 - val_accuracy: 0.4618 - val_loss: 1.3524\n",
      "Epoch 17/20\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1094s\u001b[0m 1s/step - accuracy: 0.4786 - loss: 1.3110 - val_accuracy: 0.4616 - val_loss: 1.3524\n",
      "Epoch 18/20\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m885s\u001b[0m 1s/step - accuracy: 0.4850 - loss: 1.3005 - val_accuracy: 0.4627 - val_loss: 1.3490\n",
      "Epoch 19/20\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1149s\u001b[0m 1s/step - accuracy: 0.4855 - loss: 1.2971 - val_accuracy: 0.4613 - val_loss: 1.3521\n",
      "Epoch 20/20\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m904s\u001b[0m 1s/step - accuracy: 0.4867 - loss: 1.2929 - val_accuracy: 0.4644 - val_loss: 1.3517\n",
      "\u001b[1m3073/3073\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 23ms/step - accuracy: 0.4629 - loss: 1.3546\n",
      "Test Accuracy: 0.4644\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "with np.load(\"mcts_nn_dataset_2_Feb.npz\") as data:\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "\n",
    "# Normalize and preprocess data\n",
    "X = X.astype('float32')\n",
    "y = y.astype('int32')\n",
    "\n",
    "# Ensure model only plays +1 moves by flipping -1 moves\n",
    "X[y < 0] *= -1  # Flip board for -1 moves\n",
    "y = np.abs(y)   # Convert all labels to positive moves\n",
    "\n",
    "# Convert board to 6x7x2 representation to allow overlapping boxes\n",
    "X_expanded = np.zeros((X.shape[0], 6, 7, 2), dtype=np.float32)\n",
    "X_expanded[..., 0] = (X == 1).astype(np.float32)  # Layer for player 1\n",
    "X_expanded[..., 1] = (X == -1).astype(np.float32)  # Layer for player -1\n",
    "X = X_expanded\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optimized Transformer Model with Overlapping Boxes\n",
    "def transformer_model(input_shape=(6, 7, 2), num_classes=7):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "\n",
    "    # Reshape for Transformer Input\n",
    "    x = layers.Reshape((6 * 7, 64))(x)  # Reduce feature dimensions to speed up training\n",
    "\n",
    "    # Transformer Encoder Layers\n",
    "    transformer_dim = 64  # Reduced from 512 to speed up training\n",
    "    for _ in range(2):  # Reduced transformer layers\n",
    "        attn_output = layers.MultiHeadAttention(num_heads=4, key_dim=transformer_dim)(x, x)  # Fewer attention heads\n",
    "        attn_output = layers.Dense(transformer_dim)(attn_output)  # Ensure same shape after attention\n",
    "        x = layers.Add()([x, attn_output])\n",
    "        x = layers.LayerNormalization()(x)\n",
    "        feed_forward = layers.Dense(transformer_dim, activation='relu')(x)  # Match transformer_dim instead of *2\n",
    "        x = layers.Add()([x, feed_forward])\n",
    "        x = layers.LayerNormalization()(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)  # Reduced FC layer size\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    # Fully connected output layer\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Build the optimized model\n",
    "model = transformer_model()\n",
    "\n",
    "# Compile model with learning rate decay\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.001, decay_steps=5000, decay_rate=0.9)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                    epochs=20, batch_size=500)  # Increased batch size for faster training\n",
    "\n",
    "# Evaluate test accuracy\n",
    "test_loss, test_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "model.save(\"MYGTransformer.keras\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCTS Bot Integration\n",
    "\n",
    "def update_board(board_temp, color, column):\n",
    "    board = board_temp.copy()\n",
    "    colsum = sum(abs(board[i, column]) for i in range(6))\n",
    "    row = int(5 - colsum)\n",
    "    if row >= 0:\n",
    "        board[row, column] = 1 if color == 'plus' else -1\n",
    "    return board\n",
    "\n",
    "\n",
    "def check_for_win(board):\n",
    "    for col in range(7):\n",
    "        for row in reversed(range(6)):\n",
    "            if abs(board[row, col]) < 0.1:\n",
    "                break\n",
    "            if row <= 2:\n",
    "                if sum(board[row + i, col] for i in range(4)) == 4:\n",
    "                    return 'v-plus'\n",
    "                if sum(board[row + i, col] for i in range(4)) == -4:\n",
    "                    return 'v-minus'\n",
    "    return 'nobody'\n",
    "\n",
    "#updated play vs mcts\n",
    "def play_vs_mcts(model, num_games=10):\n",
    "    wins, losses = 0, 0\n",
    "    for game in range(num_games):\n",
    "        board = np.zeros((6, 7), dtype=np.float32)\n",
    "        print(f\"\\n Starting Game {game + 1}\")\n",
    "\n",
    "        for turn in range(42):\n",
    "            player = 'plus' if turn % 2 == 0 else 'minus'\n",
    "            \n",
    "            # Expand board correctly\n",
    "            board_input = np.expand_dims(board, axis=0)  \n",
    "            board_input = np.expand_dims(board_input, axis=-1)\n",
    "            board_input = np.concatenate([board_input == 1, board_input == -1], axis=-1).astype(np.float32)\n",
    "            \n",
    "            move_probs = model.predict(board_input)[0]\n",
    "            move = np.argmax(move_probs)  # Pick best move\n",
    "            \n",
    "            print(f\"Move {turn+1}: Player {player} chooses column {move}\")\n",
    "\n",
    "            board = update_board(board, player, move)\n",
    "            winner = check_for_win(board)\n",
    "\n",
    "            if winner == 'v-plus':\n",
    "                wins += 1\n",
    "                print(f\"Model won Game {game + 1}\")\n",
    "                break\n",
    "            elif winner == 'v-minus':\n",
    "                losses += 1\n",
    "                print(f\" Model lost Game {game + 1}\")\n",
    "                break\n",
    "\n",
    "    print(f\"\\n Model won {wins}/{num_games} games vs. MCTS bot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
